{'abs_3d': True,
 'adam_beta2': 0.999,
 'apply_zero_mask': False,
 'arch': 'unet',
 'augment_type': 'none',
 'avg_model_beta': 0.9999,
 'batch_size': 64,
 'clip_range': 6.0,
 'cond_mask_prob': 0.1,
 'cuda': True,
 'data_dir': '',
 'dataset': 'permo',
 'device': 0,
 'diffusion_steps': 1000,
 'dim_mults': (2, 2, 2, 2),
 'drop_redundant': False,
 'emb_trans_dec': False,
 'eval_batch_size': 32,
 'eval_during_training': False,
 'eval_mode': 'wo_mm',
 'eval_num_samples': 1000,
 'eval_rep_times': 3,
 'eval_split': 'test',
 'eval_use_avg': True,
 'ff_size': 1024,
 'full_traj_inpaint': False,
 'grad_clip': 1.0,
 'guidance_param': 2.5,
 'impute_until': None,
 'keyframe_conditioned': True,
 'keyframe_mask_prob': 0.1,
 'keyframe_selection_scheme': 'random_frames',
 'lambda_fc': 0.0,
 'lambda_rcxyz': 0.0,
 'lambda_vel': 0.0,
 'latent_dim': 512,
 'layers': 8,
 'log_interval': 1000,
 'lr': 0.0001,
 'lr_anneal_steps': 0,
 'model_path': '',
 'noise_schedule': 'cosine',
 'num_frames': 224,
 'num_steps': 1200000,
 'only_text': True,
 'out_mult': False,
 'overwrite': False,
 'predict_xstart': True,
 'random_proj_scale': 10.0,
 'resume_checkpoint': '',
 'save_dir': 'save/3obfzp4j',
 'save_interval': 50000,
 'seed': 10,
 'sigma_small': True,
 'skip_first': None,
 'std_scale_shift': (1.0, 0.0),
 'styenc_dir': None,
 'time_weighted_loss': False,
 'train_platform_type': 'NoPlatform',
 'train_x0_as_eps': False,
 'traj_extra_weight': 1.0,
 'traj_only': False,
 'unconstrained': False,
 'unet_adagn': True,
 'unet_zero': True,
 'use_ddim': False,
 'use_fp16': True,
 'use_random_proj': False,
 'weight_decay': 0.01,
 'xz_only': False,
 'zero_keyframe_loss': False}
creating data loader...
Reading ././dataset/permo_opt.txt
WARNING: max_motion_length is set to 224
Loading dataset permo ...
mode = text_only
t2m dataset aug: none std_scale_shift: (1.0, 0.0)
t2m dataset drop redundant information: False
Pointer Pointing at 0
creating model and diffusion...
Using UNET with lantent dim:  512  and mults:  (2, 2, 2, 2)
dims:  [263, 1024, 1024, 1024, 1024] mults:  (2, 2, 2, 2)
[ models/temporal ] Channel dimensions: [(263, 1024), (1024, 1024), (1024, 1024), (1024, 1024)]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4186/4186 [00:01<00:00, 3765.67it/s]
Total params: 234.86M
Training...
train steps: 1200000
Starting epoch 0

 14%|████████████████████▉                                                                                                                                | 9/64 [00:05<00:32,  1.69it/s]
Traceback (most recent call last):
  File "train/train_condmdi.py", line 100, in <module>
    main()
  File "train/train_condmdi.py", line 95, in main
    TrainLoop(args, model, diffusion, data).run_loop()
  File "/root/autodl-tmp/MotionTransition3/MotionTransition/train/training_loop.py", line 255, in run_loop
    self.run_step(motion, cond)
  File "/root/autodl-tmp/MotionTransition3/MotionTransition/train/training_loop.py", line 333, in run_step
    self.forward_backward(batch, cond)
  File "/root/autodl-tmp/MotionTransition3/MotionTransition/train/training_loop.py", line 426, in forward_backward
    self.scaler.scale(loss).backward()
  File "/root/miniconda3/envs/CondMDI/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/root/miniconda3/envs/CondMDI/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt